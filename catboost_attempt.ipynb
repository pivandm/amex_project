{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import catboost\n",
    "\n",
    "file = open('cat_cols.txt', 'rb')\n",
    "cat_cols = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "\n",
    "# function to convert dtypes\n",
    "def encode_cat(x):\n",
    "    if isinstance(x, float):\n",
    "        return str(x)\n",
    "def dt_converter(dtype):\n",
    "    if dtype == 'float64':\n",
    "        return 'float16'\n",
    "    elif dtype == 'int64':\n",
    "        return 'int16'\n",
    "    else:\n",
    "        return 'object'\n",
    "\n",
    "def mem_usage_gb(df):\n",
    "    return round((df.memory_usage(deep=True).sum()/1073741824), 2)\n",
    "\n",
    "def file_mem_usage_gb(file_name):\n",
    "    return round((os.stat(file_name).st_size/1073741824), 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I pre-processed data in different file and saved to csv, now I only have to open it\n",
    "but there is an issue with dtypes\n",
    "beforehand I had dtypes_dict to convert float64 to float16 to reduce mem usage\n",
    "now columns are named differently and I have to redo the conversion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('prep_catboost_train.csv')\n",
    "display(train_data.head())\n",
    "print('DataFrame memory usage:', mem_usage_gb(train_data), 'GB    ', 'File size:', file_mem_usage_gb('prep_catboost_train.csv'), 'GB')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset is too big should be around 1 GB got 3.23 GB\n",
    "This is because dtypes by default are float64, int64, lets deal with that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dt = train_data.dtypes\n",
    "dt.unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are only 3 dtypes in the DataFrame, converting should be easy\n",
    "Create dict {col_name : dtype} to convert while reading from file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dtype_dict = dict(zip(dt.keys().tolist(), list(map(dt_converter, dt.values.tolist()))))\n",
    "del dt\n",
    "gc.collect()\n",
    "dtype_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now load DataFrame again using dtype_dict to convert dtypes\n",
    "and compare memory usage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('prep_catboost_train.csv', dtype=dtype_dict)\n",
    "print('DataFrame memory usage:', mem_usage_gb(train_data), 'GB    ', 'File size:', file_mem_usage_gb('prep_catboost_train.csv'), 'GB')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv', dtype={'target': 'int8'})\n",
    "train_labels.drop(columns=['customer_ID'], inplace=True)\n",
    "train_labels = np.ravel(train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categoricals for catboost should be str or int, yet some are float\n",
    "lets change that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nulls = train_data[cat_cols].isna().sum(); types = train_data[cat_cols].dtypes\n",
    "cat_stats = pd.concat([nulls, types], axis=1).rename(columns={0: \"NaN_count\", 1: \"type\"})\n",
    "cat_stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_to_encode = cat_stats.loc[(cat_stats['NaN_count'] != 0) | (cat_stats['type'] == 'float16')].index.tolist()\n",
    "cols_to_encode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in cols_to_encode:\n",
    "    train_data[col] = train_data[col].astype('object')\n",
    "    train_data[col] = train_data[col].map(str)\n",
    "train_data[cat_cols].fillna('no_data', inplace=True)\n",
    "train_data.drop(columns=['customer_ID'], inplace=True)\n",
    "train_data[cat_cols].dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nulls = train_data[cat_cols].isna().sum(); types = train_data[cat_cols].dtypes\n",
    "cat_stats = pd.concat([nulls, types], axis=1).rename(columns={0: \"NaN_count\", 1: \"type\"})\n",
    "cat_stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.04,\n",
    "    'n_estimators': 1100,\n",
    "    'num_leaves': 127,\n",
    "    'task_type': 'GPU'\n",
    "}\n",
    "model = catboost.CatBoostRegressor(bagging_temperature = 0.2,\n",
    "                                   od_type='Iter',\n",
    "                                   metric_period = 50,\n",
    "                                   od_wait=20,\n",
    "                                   iterations=3000)\n",
    "model.fit(train_data, train_labels, cat_features=cat_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('prep_catboost_test.csv', dtype=dtype_dict)\n",
    "nulls = test_data[cat_cols].isna().sum(); types = test_data[cat_cols].dtypes\n",
    "cat_stats = pd.concat([nulls, types], axis=1).rename(columns={0: \"NaN_count\", 1: \"type\"})\n",
    "cols_to_encode = cat_stats.loc[(cat_stats['NaN_count'] != 0) | (cat_stats['type'] == 'float16')].index.tolist()\n",
    "\n",
    "for col in cols_to_encode:\n",
    "    test_data[col] = test_data[col].astype('object')\n",
    "    test_data[col] = test_data[col].map(str)\n",
    "test_data[cat_cols].fillna('no_data', inplace=True)\n",
    "test_data.drop(columns=['customer_ID'], inplace=True)\n",
    "test_data[cat_cols].dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "# loaded_model = joblib.load('model_third.joblib')\n",
    "predictions = model.predict(test_data)\n",
    "# p_clipped = np.clip(predictions, 0.025, 0.975)\n",
    "output_file = pd.DataFrame({'customer_ID': sample.customer_ID, 'prediction': predictions})\n",
    "# output_file.to_csv('submission_dart.csv', index= False)\n",
    "import os\n",
    "import joblib\n",
    "dir_name = str(input('Specify directory name: '))\n",
    "model_name = str(input('Specify model name: '))\n",
    "full_model_name = model_name + '.joblib'\n",
    "directory = 'total_output_' + dir_name\n",
    "parent_dir = 'C:/Users/boomb/DataspellProjects/dsProject_1/'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "os.mkdir(path)\n",
    "open(os.path.join(path, full_model_name), 'x').close()\n",
    "with open(os.path.join(path, (model_name + '_params.txt')), 'w') as fp:\n",
    "    fp.write(str(params))\n",
    "sub_name = 'submission_' + str(input(\"Specify sub name: \")) + '.csv'\n",
    "open(os.path.join(path, sub_name), 'x').close()\n",
    "output_file.to_csv(os.path.join(path, sub_name), index=False)\n",
    "joblib.dump(model, os.path.join(path, full_model_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_file.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "import  xgboost as xgb\n",
    "# import os\n",
    "# import sys\n",
    "import gc\n",
    "# import catboost\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# file = open('cat_cols.txt', 'rb')\n",
    "# cat_cols = pickle.load(file)\n",
    "# file.close()\n",
    "class CONFIG:\n",
    "\n",
    "    \"\"\"\n",
    "    Configuration of training\n",
    "\n",
    "    params: dict = Parameters of Tree Booster\n",
    "\n",
    "    n_folds: int = number of splits for Stratified K-Folds\n",
    "\n",
    "    n_rounds: int = number of boosting iterations\n",
    "\n",
    "    early_stopping: int = stop if there is little to no improvement\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters of Tree Booster\n",
    "    params = {\n",
    "        'eta': 0.0175,\n",
    "        'gamma': 0,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 1,\n",
    "        'max_delta_step': 1, #suggested by xgb documentation for imbalanced dataset\n",
    "        'max_leaves': 100,\n",
    "        'objective': 'binary:logistic',\n",
    "        'disable_default_eval_metric': 1,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "    # number of folds\n",
    "    n_folds = 5\n",
    "    n_rounds = 6000\n",
    "    early_stopping = 3000\n",
    "    verbose_eval = 300\n",
    "    def output(self):\n",
    "        print('=' * 60)\n",
    "        print('CONFIGURATION')\n",
    "        print('=' * 60)\n",
    "        print('Tree Booster parameters: ')\n",
    "        for k, v in self.params.items():\n",
    "            print(f'{k}: {v}')\n",
    "        print(f'Number of boosting rounds: {self.n_rounds}')\n",
    "        print(f'Early stopping rounds: {self.early_stopping}')\n",
    "        print(f'Stratified K-Fold number of splits: {self.n_folds}')\n",
    "        print('=' * 60)\n",
    "        print('END')\n",
    "        print('=' * 60)\n",
    "def one_hot(train, test):\n",
    "    \"\"\"\n",
    "    Simple encoding using pandas.DataFrame.get_dummies()\n",
    "\n",
    "    !!! If some values do not appear in both datasets in same column\n",
    "    function will not work correctly. Check that test and train have same columns !!!\n",
    "\n",
    "    :param train: train dataset <- pandas.DataFrame\n",
    "    :param test: test dataset <- pandas.DataFrame\n",
    "    :return: same datasets with one hot encoded categoricals -> tuple[pandas.DataFrame, pandas.DataFrame]\n",
    "    \"\"\"\n",
    "    c_enc = train.columns.to_series().groupby(train.dtypes).groups[np.dtype('object')].tolist()\n",
    "    for col in c_enc:\n",
    "        dummies = pd.get_dummies(train[col], prefix=col, drop_first=False)\n",
    "        train = pd.concat([train, dummies], axis=1)\n",
    "        train.drop(columns=col, inplace=True)\n",
    "        dummies = pd.get_dummies(test[col], prefix=col, drop_first=False)\n",
    "        test = pd.concat([test, dummies], axis=1)\n",
    "        test.drop(columns=col, inplace=True)\n",
    "    gc.collect()\n",
    "    return train, test\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Amex Kaggle Competition Metric\n",
    "    :param y_true: true labels\n",
    "    :param y_pred: predicted values\n",
    "    :return: metric score -> float\n",
    "    \"\"\"\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "def xgb_amex_metric(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
    "    \"\"\"\n",
    "    Custom Metric for XGBoost\n",
    "    using Amex Metric\n",
    "    :param predt: predicted values <- np.ndarray\n",
    "    :param dtrain: matrix to get labels (true values) from <- xgb.Dmatrix\n",
    "    :return: name of the metric, score -> tuple[str, float]\n",
    "    \"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, predt)\n",
    "\n",
    "def mem_usage_gb(df: pandas.DataFrame, deep: bool):\n",
    "    \"\"\"\n",
    "    Memory usage of DataFrame\n",
    "    :param df: dataset <- pandas.DataFrame\n",
    "    :param deep: parameter of pandas.DataFrame.memory_usage(deep=) <- bool\n",
    "    :return: rounded memory usage in GB -> float\n",
    "    \"\"\"\n",
    "    return round((df.memory_usage(deep=deep).sum()/1073741824), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_dataframes(message: str):\n",
    "    print(message)\n",
    "    file = open('dtype_for_agg_catb.txt', 'rb')\n",
    "    dtypes = pickle.load(file)\n",
    "    file.close()\n",
    "    train = pd.read_csv('prep_catboost_train.csv', dtype=dtypes)\n",
    "    train.drop(columns=['customer_ID'], inplace=True)\n",
    "    test = pd.read_csv('prep_catboost_test.csv', dtype=dtypes)\n",
    "    test.drop(columns=['customer_ID'], inplace=True)\n",
    "    train, test = one_hot(train, test)\n",
    "    idx = train.columns.get_loc('D_64_last_-1')\n",
    "    test.insert(loc=idx, column='D_64_last_-1', value=[0] * len(test))\n",
    "    test['D_64_last_-1'] = test['D_64_last_-1'].astype('uint8')\n",
    "    print('encoded cols in train, test')\n",
    "    display(train.dtypes.loc[train.dtypes == 'uint8'], test.dtypes.loc[test.dtypes == 'uint8'])\n",
    "    deep = True\n",
    "    print('train dataset mem usage:', mem_usage_gb(train, deep), 'GB')\n",
    "    print('test dataset mem usage:', mem_usage_gb(test, deep), 'GB')\n",
    "    labels = pd.read_csv('train_labels.csv', dtype={'target': 'int8'})\n",
    "    labels.drop(columns=['customer_ID'], inplace=True)\n",
    "    labels = np.ravel(labels)\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    count_dict = dict(zip(unique, counts))\n",
    "    for k, v in count_dict.items():\n",
    "        print(f'Number of {k} in train_labels: {v}')\n",
    "        print(f'percentage of {k} in train_labels: {int(round(v / len(labels), 2)) * 100}%')\n",
    "    print('datasets loaded, total mem usage: ', mem_usage_gb(train, deep) + mem_usage_gb(test, deep), 'GB')\n",
    "    del deep, unique, counts, count_dict\n",
    "    gc.collect()\n",
    "    return train, test, labels\n",
    "def get_predictions(train_data, test_data, train_labels):\n",
    "    total_predictions = np.zeros(test_data.shape[0])\n",
    "    CONFIG().output()\n",
    "    print('Start training...')\n",
    "    results = dict()\n",
    "    skf = StratifiedKFold(n_splits=CONFIG.n_folds)\n",
    "    n = 1\n",
    "    for train_index, test_index in skf.split(train_data, train_labels):\n",
    "        print('=' * 60)\n",
    "        print(f'Fold number: {n}')\n",
    "        print('=' * 60)\n",
    "        # Get counts of 0 and 1 in K-Fold labels\n",
    "        unique, counts = np.unique(train_labels[train_index], return_counts=True)\n",
    "        count_dict = dict(zip(unique, counts))\n",
    "        for k, v in count_dict.items():\n",
    "            print(f'Number of {k} in train_labels: {v}')\n",
    "            print(f'percentage of {k} in train_labels: {int(round(v / len(train_labels[train_index]), 2)) * 100}%')\n",
    "        unique, counts = np.unique(train_labels[test_index], return_counts=True)\n",
    "        count_dict = dict(zip(unique, counts))\n",
    "        for k, v in count_dict.items():\n",
    "            print(f'Number of {k} in test(eval)_labels: {v}')\n",
    "            print(f'percentage of {k} in test(eval)_labels: {int(round(v / len(train_labels[test_index]), 2)) * 100}%')\n",
    "        print('=' * 60)\n",
    "        del unique, counts, count_dict\n",
    "        gc.collect()\n",
    "        n += 1\n",
    "        d_train = xgb.DMatrix(train_data.iloc[train_index], train_labels[train_index])\n",
    "        d_test = xgb.DMatrix(train_data.iloc[test_index], train_labels[test_index])\n",
    "        model = xgb.train(CONFIG.params,\n",
    "                          dtrain= d_train,\n",
    "                          num_boost_round= CONFIG.n_rounds,\n",
    "                          evals= [(d_train, 'train'), (d_test, 'eval')],\n",
    "                          custom_metric= xgb_amex_metric,\n",
    "                          early_stopping_rounds= CONFIG.early_stopping,\n",
    "                          evals_result= results,\n",
    "                          verbose_eval= CONFIG.verbose_eval,\n",
    "                          )\n",
    "        d_out = xgb.DMatrix(test_data)\n",
    "        fold_out_predictions = model.predict(d_out)\n",
    "        # adjust predictions according to n_folds\n",
    "        total_predictions += fold_out_predictions / CONFIG.n_folds\n",
    "        print('Fold model successfully trained. Predictions saved')\n",
    "    del d_train, d_test\n",
    "    gc.collect()\n",
    "    sample = pd.read_csv('sample_submission.csv')\n",
    "    output = pd.DataFrame({'customer_ID': sample.customer_ID, 'prediction': total_predictions})\n",
    "    return output, results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "first\\\n",
    "eta = 0.04\n",
    "n_rounds = 1200\n",
    "early_stopping = 600\n",
    "second\\\n",
    "eta = 0.03\n",
    "n_rounds = 3000\n",
    "early stopping = 1500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivan Piiashev trying ML\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dtype_for_agg_catb.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_d, test_d, train_l \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataframes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mIvan Piiashev trying ML\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m, in \u001B[0;36mload_dataframes\u001B[1;34m(message)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_dataframes\u001B[39m(message: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(message)\n\u001B[1;32m----> 3\u001B[0m     file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdtype_for_agg_catb.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     dtypes \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(file)\n\u001B[0;32m      5\u001B[0m     file\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\.conda\\envs\\newConda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m     )\n\u001B[1;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'dtype_for_agg_catb.txt'"
     ]
    }
   ],
   "source": [
    "train_d, test_d, train_l = load_dataframes('Ivan Piiashev trying ML')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ofile, result = get_predictions(train_d, test_d, train_l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ofile.to_csv('sub2_k_folds.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

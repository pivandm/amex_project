{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_data_new.csv')\n",
    "print(1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data_train():\n",
    "    train = pd.read_csv('train_data_3,5.csv')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        print(1)\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float16)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        print(1)\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "\n",
    "    train.to_csv('train_lgbt1.csv')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data_train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_difference1(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "def read_preprocess_data_test():\n",
    "    test = pd.read_csv('test_data.csv')\n",
    "    features = test.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        print(1)\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float16)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int16)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference1(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    test.to_csv('test_lgbt.csv')\n",
    "read_preprocess_data_test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jopa= pd.read_csv('train_lgbt.csv')\n",
    "jopa.info(memory_usage=\"deep\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dtype_dict = {\n",
    "    'P_2': 'float16',\n",
    "    'D_39': 'float16',\n",
    "    'B_1': 'float16',\n",
    "    'B_2': 'float16',\n",
    "    'R_1': 'float16',\n",
    "    'S_3': 'float16',\n",
    "    'D_41': 'float16',\n",
    "    'B_3': 'float16',\n",
    "    'D_42': 'float16',\n",
    "    'D_43': 'float16',\n",
    "    'D_44': 'float16',\n",
    "    'B_4': 'float16',\n",
    "    'D_45': 'float16',\n",
    "    'B_5': 'float16',\n",
    "    'R_2': 'float16',\n",
    "    'D_46': 'float16',\n",
    "    'D_47': 'float16',\n",
    "    'D_48': 'float16',\n",
    "    'D_49': 'float16',\n",
    "    'B_6': 'float16',\n",
    "    'B_7': 'float16',\n",
    "    'B_8': 'float16',\n",
    "    'D_50': 'float16',\n",
    "    'D_51': 'float16',\n",
    "    'B_9': 'float16',\n",
    "    'R_3': 'float16',\n",
    "    'D_52': 'float16',\n",
    "    'P_3': 'float16',\n",
    "    'B_10': 'float16',\n",
    "    'D_53': 'float16',\n",
    "    'S_5': 'float16',\n",
    "    'B_11': 'float16',\n",
    "    'S_6': 'float16',\n",
    "    'D_54': 'float16',\n",
    "    'R_4': 'float16',\n",
    "    'S_7': 'float16',\n",
    "    'B_12': 'float16',\n",
    "    'S_8': 'float16',\n",
    "    'D_55': 'float16',\n",
    "    'D_56': 'float16',\n",
    "    'B_13': 'float16',\n",
    "    'R_5': 'float16',\n",
    "    'D_58': 'float16',\n",
    "    'S_9': 'float16',\n",
    "    'B_14': 'float16',\n",
    "    'D_59': 'float16',\n",
    "    'D_60': 'float16',\n",
    "    'D_61': 'float16',\n",
    "    'B_15': 'float16',\n",
    "    'S_11': 'float16',\n",
    "    'D_62': 'float16',\n",
    "    'D_63': 'object',\n",
    "    'D_64': 'object',\n",
    "    'D_65': 'float16',\n",
    "    'B_16': 'float16',\n",
    "    'B_17': 'float16',\n",
    "    'B_18': 'float16',\n",
    "    'B_19': 'float16',\n",
    "    'D_66': 'float16',\n",
    "    'B_20': 'float16',\n",
    "    'D_68': 'float16',\n",
    "    'S_12': 'float16',\n",
    "    'R_6': 'float16',\n",
    "    'S_13': 'float16',\n",
    "    'B_21': 'float16',\n",
    "    'D_69': 'float16',\n",
    "    'B_22': 'float16',\n",
    "    'D_70': 'float16',\n",
    "    'D_71': 'float16',\n",
    "    'D_72': 'float16',\n",
    "    'S_15': 'float16',\n",
    "    'B_23': 'float16',\n",
    "    'D_73': 'float16',\n",
    "    'P_4': 'float16',\n",
    "    'D_74': 'float16',\n",
    "    'D_75': 'float16',\n",
    "    'D_76': 'float16',\n",
    "    'B_24': 'float16',\n",
    "    'R_7': 'float16',\n",
    "    'D_77': 'float16',\n",
    "    'B_25': 'float16',\n",
    "    'B_26': 'float16',\n",
    "    'D_78': 'float16',\n",
    "    'D_79': 'float16',\n",
    "    'R_8': 'float16',\n",
    "    'R_9': 'float16',\n",
    "    'S_16': 'float16',\n",
    "    'D_80': 'float16',\n",
    "    'R_10': 'float16',\n",
    "    'R_11': 'float16',\n",
    "    'B_27': 'float16',\n",
    "    'D_81': 'float16',\n",
    "    'D_82': 'float16',\n",
    "    'S_17': 'float16',\n",
    "    'R_12': 'float16',\n",
    "    'B_28': 'float16',\n",
    "    'R_13': 'float16',\n",
    "    'D_83': 'float16',\n",
    "    'R_14': 'float16',\n",
    "    'R_15': 'float16',\n",
    "    'D_84': 'float16',\n",
    "    'R_16': 'float16',\n",
    "    'B_29': 'float16',\n",
    "    'B_30': 'float16',\n",
    "    'S_18': 'float16',\n",
    "    'D_86': 'float16',\n",
    "    'D_87': 'float16',\n",
    "    'R_17': 'float16',\n",
    "    'R_18': 'float16',\n",
    "    'D_88': 'float16',\n",
    "    'B_31': 'int64',\n",
    "    'S_19': 'float16',\n",
    "    'R_19': 'float16',\n",
    "    'B_32': 'float16',\n",
    "    'S_20': 'float16',\n",
    "    'R_20': 'float16',\n",
    "    'R_21': 'float16',\n",
    "    'B_33': 'float16',\n",
    "    'D_89': 'float16',\n",
    "    'R_22': 'float16',\n",
    "    'R_23': 'float16',\n",
    "    'D_91': 'float16',\n",
    "    'D_92': 'float16',\n",
    "    'D_93': 'float16',\n",
    "    'D_94': 'float16',\n",
    "    'R_24': 'float16',\n",
    "    'R_25': 'float16',\n",
    "    'D_96': 'float16',\n",
    "    'S_22': 'float16',\n",
    "    'S_23': 'float16',\n",
    "    'S_24': 'float16',\n",
    "    'S_25': 'float16',\n",
    "    'S_26': 'float16',\n",
    "    'D_102': 'float16',\n",
    "    'D_103': 'float16',\n",
    "    'D_104': 'float16',\n",
    "    'D_105': 'float16',\n",
    "    'D_106': 'float16',\n",
    "    'D_107': 'float16',\n",
    "    'B_36': 'float16',\n",
    "    'B_37': 'float16',\n",
    "    'R_26': 'float16',\n",
    "    'R_27': 'float16',\n",
    "    'B_38': 'float16',\n",
    "    'D_108': 'float16',\n",
    "    'D_109': 'float16',\n",
    "    'D_110': 'float16',\n",
    "    'D_111': 'float16',\n",
    "    'B_39': 'float16',\n",
    "    'D_112': 'float16',\n",
    "    'B_40': 'float16',\n",
    "    'S_27': 'float16',\n",
    "    'D_113': 'float16',\n",
    "    'D_114': 'float16',\n",
    "    'D_115': 'float16',\n",
    "    'D_116': 'float16',\n",
    "    'D_117': 'float16',\n",
    "    'D_118': 'float16',\n",
    "    'D_119': 'float16',\n",
    "    'D_120': 'float16',\n",
    "    'D_121': 'float16',\n",
    "    'D_122': 'float16',\n",
    "    'D_123': 'float16',\n",
    "    'D_124': 'float16',\n",
    "    'D_125': 'float16',\n",
    "    'D_126': 'float16',\n",
    "    'D_127': 'float16',\n",
    "    'D_128': 'float16',\n",
    "    'D_129': 'float16',\n",
    "    'B_41': 'float16',\n",
    "    'B_42': 'float16',\n",
    "    'D_130': 'float16',\n",
    "    'D_131': 'float16',\n",
    "    'D_132': 'float16',\n",
    "    'D_133': 'float16',\n",
    "    'R_28': 'float16',\n",
    "    'D_134': 'float16',\n",
    "    'D_135': 'float16',\n",
    "    'D_136': 'float16',\n",
    "    'D_137': 'float16',\n",
    "    'D_138': 'float16',\n",
    "    'D_139': 'float16',\n",
    "    'D_140': 'float16',\n",
    "    'D_141': 'float16',\n",
    "    'D_142': 'float16',\n",
    "    'D_143': 'float16',\n",
    "    'D_144': 'float16',\n",
    "    'D_145': 'float16'}\n",
    "test = pd.read_csv('test_data.csv', dtype = dtype_dict)\n",
    "test.to_csv('test_7,2gb.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '/content/data/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    for cat_col in cat_features:\n",
    "        encoder = LabelEncoder()\n",
    "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "        test[cat_col] = encoder.transform(test[cat_col])\n",
    "    # Round last float features to 2 decimal place\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    num_cols = [col for col in num_cols if 'last' in col]\n",
    "    for col in num_cols:\n",
    "        train[col + '_round2'] = train[col].round(2)\n",
    "        test[col + '_round2'] = test[col].round(2)\n",
    "    # Get the difference between last and mean\n",
    "    num_cols = [col for col in train.columns if 'last' in col]\n",
    "    num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "            test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "        except:\n",
    "            pass\n",
    "    # Transform float64 and float32 to float16\n",
    "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "    for col in tqdm(num_cols):\n",
    "        train[col] = train[col].astype(np.float16)\n",
    "        test[col] = test[col].astype(np.float16)\n",
    "    # Get feature list\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': CFG.metric,\n",
    "        'boosting': CFG.boosting_type,\n",
    "        'seed': CFG.seed,\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.20,\n",
    "        'bagging_freq': 10,\n",
    "        'bagging_fraction': 0.50,\n",
    "        'n_jobs': -1,\n",
    "        'lambda_l2': 2,\n",
    "        'min_data_in_leaf': 40,\n",
    "    }\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            num_boost_round = 10500,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 1500,\n",
    "            verbose_eval = 500,\n",
    "            feval = lgb_amex_metric\n",
    "        )\n",
    "        # Save best model\n",
    "        joblib.dump(model, f'/content/drive/MyDrive/Amex/Models/lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "        val_pred = model.predict(x_val)\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[val_ind] = val_pred\n",
    "        # Predict the test set\n",
    "        test_pred = model.predict(test[features])\n",
    "        test_predictions += test_pred / CFG.n_folds\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "    # Compute out of folds metric\n",
    "    score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    print(f'Our out of folds CV score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "    oof_df.to_csv(f'/content/drive/MyDrive/Amex/OOF/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    # Create a dataframe to store test prediction\n",
    "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "    test_df.to_csv(f'/content/drive/MyDrive/Amex/Predictions/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seed_everything(42)\n",
    "#train, test = read_data()\n",
    "#train_and_evaluate(train, test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

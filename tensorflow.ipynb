{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras as k\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "dtype_dict = {\n",
    "    'P_2': 'float16',\n",
    "    'D_39': 'float16',\n",
    "    'B_1': 'float16',\n",
    "    'B_2': 'float16',\n",
    "    'R_1': 'float16',\n",
    "    'S_3': 'float16',\n",
    "    'D_41': 'float16',\n",
    "    'B_3': 'float16',\n",
    "    'D_42': 'float16',\n",
    "    'D_43': 'float16',\n",
    "    'D_44': 'float16',\n",
    "    'B_4': 'float16',\n",
    "    'D_45': 'float16',\n",
    "    'B_5': 'float16',\n",
    "    'R_2': 'float16',\n",
    "    'D_46': 'float16',\n",
    "    'D_47': 'float16',\n",
    "    'D_48': 'float16',\n",
    "    'D_49': 'float16',\n",
    "    'B_6': 'float16',\n",
    "    'B_7': 'float16',\n",
    "    'B_8': 'float16',\n",
    "    'D_50': 'float16',\n",
    "    'D_51': 'float16',\n",
    "    'B_9': 'float16',\n",
    "    'R_3': 'float16',\n",
    "    'D_52': 'float16',\n",
    "    'P_3': 'float16',\n",
    "    'B_10': 'float16',\n",
    "    'D_53': 'float16',\n",
    "    'S_5': 'float16',\n",
    "    'B_11': 'float16',\n",
    "    'S_6': 'float16',\n",
    "    'D_54': 'float16',\n",
    "    'R_4': 'float16',\n",
    "    'S_7': 'float16',\n",
    "    'B_12': 'float16',\n",
    "    'S_8': 'float16',\n",
    "    'D_55': 'float16',\n",
    "    'D_56': 'float16',\n",
    "    'B_13': 'float16',\n",
    "    'R_5': 'float16',\n",
    "    'D_58': 'float16',\n",
    "    'S_9': 'float16',\n",
    "    'B_14': 'float16',\n",
    "    'D_59': 'float16',\n",
    "    'D_60': 'float16',\n",
    "    'D_61': 'float16',\n",
    "    'B_15': 'float16',\n",
    "    'S_11': 'float16',\n",
    "    'D_62': 'float16',\n",
    "    'D_63': 'object',\n",
    "    'D_64': 'object',\n",
    "    'D_65': 'float16',\n",
    "    'B_16': 'float16',\n",
    "    'B_17': 'float16',\n",
    "    'B_18': 'float16',\n",
    "    'B_19': 'float16',\n",
    "    'D_66': 'float16',\n",
    "    'B_20': 'float16',\n",
    "    'D_68': 'float16',\n",
    "    'S_12': 'float16',\n",
    "    'R_6': 'float16',\n",
    "    'S_13': 'float16',\n",
    "    'B_21': 'float16',\n",
    "    'D_69': 'float16',\n",
    "    'B_22': 'float16',\n",
    "    'D_70': 'float16',\n",
    "    'D_71': 'float16',\n",
    "    'D_72': 'float16',\n",
    "    'S_15': 'float16',\n",
    "    'B_23': 'float16',\n",
    "    'D_73': 'float16',\n",
    "    'P_4': 'float16',\n",
    "    'D_74': 'float16',\n",
    "    'D_75': 'float16',\n",
    "    'D_76': 'float16',\n",
    "    'B_24': 'float16',\n",
    "    'R_7': 'float16',\n",
    "    'D_77': 'float16',\n",
    "    'B_25': 'float16',\n",
    "    'B_26': 'float16',\n",
    "    'D_78': 'float16',\n",
    "    'D_79': 'float16',\n",
    "    'R_8': 'float16',\n",
    "    'R_9': 'float16',\n",
    "    'S_16': 'float16',\n",
    "    'D_80': 'float16',\n",
    "    'R_10': 'float16',\n",
    "    'R_11': 'float16',\n",
    "    'B_27': 'float16',\n",
    "    'D_81': 'float16',\n",
    "    'D_82': 'float16',\n",
    "    'S_17': 'float16',\n",
    "    'R_12': 'float16',\n",
    "    'B_28': 'float16',\n",
    "    'R_13': 'float16',\n",
    "    'D_83': 'float16',\n",
    "    'R_14': 'float16',\n",
    "    'R_15': 'float16',\n",
    "    'D_84': 'float16',\n",
    "    'R_16': 'float16',\n",
    "    'B_29': 'float16',\n",
    "    'B_30': 'float16',\n",
    "    'S_18': 'float16',\n",
    "    'D_86': 'float16',\n",
    "    'D_87': 'float16',\n",
    "    'R_17': 'float16',\n",
    "    'R_18': 'float16',\n",
    "    'D_88': 'float16',\n",
    "    'B_31': 'int64',\n",
    "    'S_19': 'float16',\n",
    "    'R_19': 'float16',\n",
    "    'B_32': 'float16',\n",
    "    'S_20': 'float16',\n",
    "    'R_20': 'float16',\n",
    "    'R_21': 'float16',\n",
    "    'B_33': 'float16',\n",
    "    'D_89': 'float16',\n",
    "    'R_22': 'float16',\n",
    "    'R_23': 'float16',\n",
    "    'D_91': 'float16',\n",
    "    'D_92': 'float16',\n",
    "    'D_93': 'float16',\n",
    "    'D_94': 'float16',\n",
    "    'R_24': 'float16',\n",
    "    'R_25': 'float16',\n",
    "    'D_96': 'float16',\n",
    "    'S_22': 'float16',\n",
    "    'S_23': 'float16',\n",
    "    'S_24': 'float16',\n",
    "    'S_25': 'float16',\n",
    "    'S_26': 'float16',\n",
    "    'D_102': 'float16',\n",
    "    'D_103': 'float16',\n",
    "    'D_104': 'float16',\n",
    "    'D_105': 'float16',\n",
    "    'D_106': 'float16',\n",
    "    'D_107': 'float16',\n",
    "    'B_36': 'float16',\n",
    "    'B_37': 'float16',\n",
    "    'R_26': 'float16',\n",
    "    'R_27': 'float16',\n",
    "    'B_38': 'float16',\n",
    "    'D_108': 'float16',\n",
    "    'D_109': 'float16',\n",
    "    'D_110': 'float16',\n",
    "    'D_111': 'float16',\n",
    "    'B_39': 'float16',\n",
    "    'D_112': 'float16',\n",
    "    'B_40': 'float16',\n",
    "    'S_27': 'float16',\n",
    "    'D_113': 'float16',\n",
    "    'D_114': 'float16',\n",
    "    'D_115': 'float16',\n",
    "    'D_116': 'float16',\n",
    "    'D_117': 'float16',\n",
    "    'D_118': 'float16',\n",
    "    'D_119': 'float16',\n",
    "    'D_120': 'float16',\n",
    "    'D_121': 'float16',\n",
    "    'D_122': 'float16',\n",
    "    'D_123': 'float16',\n",
    "    'D_124': 'float16',\n",
    "    'D_125': 'float16',\n",
    "    'D_126': 'float16',\n",
    "    'D_127': 'float16',\n",
    "    'D_128': 'float16',\n",
    "    'D_129': 'float16',\n",
    "    'B_41': 'float16',\n",
    "    'B_42': 'float16',\n",
    "    'D_130': 'float16',\n",
    "    'D_131': 'float16',\n",
    "    'D_132': 'float16',\n",
    "    'D_133': 'float16',\n",
    "    'R_28': 'float16',\n",
    "    'D_134': 'float16',\n",
    "    'D_135': 'float16',\n",
    "    'D_136': 'float16',\n",
    "    'D_137': 'float16',\n",
    "    'D_138': 'float16',\n",
    "    'D_139': 'float16',\n",
    "    'D_140': 'float16',\n",
    "    'D_141': 'float16',\n",
    "    'D_142': 'float16',\n",
    "    'D_143': 'float16',\n",
    "    'D_144': 'float16',\n",
    "    'D_145': 'float16'}\n",
    "data = pd.read_csv('train_data_3,5.csv', dtype = dtype_dict)\n",
    "data.drop(columns= [\"Unnamed: 0\"], inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data_3,5.csv', usecols=['customer_ID'])\n",
    "#train['customer_ID'] = train['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "train['customer_ID'] = train['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "customers = train.drop_duplicates().sort_index().values.flatten()\n",
    "print(f'There are {len(customers)} unique customers in train.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data_3,5.csv', dtype = dtype_dict)\n",
    "train.drop(columns= [\"Unnamed: 0\"], inplace = True)\n",
    "T_COLS = train.columns.tolist()\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\",\n",
    "]\n",
    "\n",
    "features = train.drop([\"customer_ID\", \"S_2\"], axis = 1).columns.to_list()\n",
    "num_features = [col for col in features if col not in cat_features]\n",
    "train['customer_ID'] = train['customer_ID'].apply(int, base = 16)\n",
    "train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last',])\n",
    "train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "train_num_agg.reset_index(inplace=True)\n",
    "train_num_agg.head(10)\n",
    "print(f'There are {len(T_COLS)} train dataframe columns')\n",
    "train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg([\"count\", \"first\", \"last\", \"nunique\"])\n",
    "train_cat_agg.columns = [\"_\".join(x) for x in train_cat_agg.columns]\n",
    "train_cat_agg.reset_index(inplace = True)\n",
    "train = pd.concat([train_num_agg, train_cat_agg], axis= 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.loc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_train_cat_agg = train_cat_agg.columns.tolist()\n",
    "list_train_cat_agg.pop(0)\n",
    "list_train_cat_agg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feature_engineer(train, PAD_CUSTOMER_TO_13_ROWS = True, targets = None):\n",
    "\n",
    "    # REDUCE STRING COLUMNS\n",
    "    # from 64 bytes to 8 bytes, and 10 bytes to 3 bytes respectively\n",
    "\n",
    "    # LABEL ENCODE CAT COLUMNS (and reduce to 1 byte)\n",
    "    # with 0: padding, 1: nan, 2,3,4,etc: values\n",
    "    d_63_map = {'CL':2, 'CO':3, 'CR':4, 'XL':5, 'XM':6, 'XZ':7}\n",
    "    train['D_63_last'] = train.D_63_last.map(d_63_map).fillna(1).astype('int16')\n",
    "    train['D_63_first'] = train.D_63_first.map(d_63_map).fillna(1).astype('int16')\n",
    "\n",
    "    d_64_map = {'-1':2,'O':3, 'R':4, 'U':5}\n",
    "    train['D_64_last'] = train.D_64_last.map(d_64_map).fillna(1).astype('int16')\n",
    "    train['D_64_first'] = train.D_64_first.map(d_64_map).fillna(1).astype('int16')\n",
    "\n",
    "    CATS = [list_train_cat_agg]\n",
    "    OFFSETS = [2,1,2,2,3,2,3,2,2] #2 minus minimal value in full train csv\n",
    "    # then 0 will be padding, 1 will be NAN, 2,3,4,etc will be values\n",
    "    for c,s in zip(CATS,OFFSETS):\n",
    "        train[c] = train[c] + s\n",
    "        train[c] = train[c].fillna(1).astype('int16')\n",
    "    CATS += ['D_63_first','D_64_last']\n",
    "\n",
    "    # ADD NEW FEATURES HERE\n",
    "    # EXAMPLE: train['feature_189'] = etc etc etc\n",
    "    # EXAMPLE: train['feature_190'] = etc etc etc\n",
    "    # IF CATEGORICAL, THEN ADD TO CATS WITH: CATS += ['feaure_190'] etc etc etc\n",
    "\n",
    "    # PAD ROWS SO EACH CUSTOMER HAS 13 ROWS\n",
    "\n",
    "\n",
    "    # ADD TARGETS (and reduce to 1 byte)\n",
    "    if targets is not None:\n",
    "        train = train.merge(targets,on='customer_ID',how='left')\n",
    "        train.target = train.target.astype('int16')\n",
    "\n",
    "    # FILL NAN\n",
    "    d_63_map = {'CL':2, 'CO':3, 'CR':4, 'XL':5, 'XM':6, 'XZ':7}\n",
    "    train['D_63'] = train.D_63.map(d_63_map).fillna(1).astype('int8')\n",
    "\n",
    "    d_64_map = {'-1':2,'O':3, 'R':4, 'U':5}\n",
    "    train['D_64'] = train.D_64.map(d_64_map).fillna(1).astype('int8')\n",
    "\n",
    "    CATS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68']\n",
    "    OFFSETS = [2,1,2,2,3,2,3,2,2] #2 minus minimal value in full train csv\n",
    "    # then 0 will be padding, 1 will be NAN, 2,3,4,etc will be values\n",
    "    for c,s in zip(CATS,OFFSETS):\n",
    "        train[c] = train[c] + s\n",
    "        train[c] = train[c].fillna(1).astype('int8')\n",
    "    CATS += ['D_63','D_64']\n",
    "\n",
    "    # SORT BY CUSTOMER THEN DATE\n",
    "    train = train.sort_values(['customer_ID','year','month','day']).reset_index(drop=True)\n",
    "    train = train.drop(['year','month','day'],axis=1)\n",
    "\n",
    "    # REARRANGE COLUMNS WITH 11 CATS FIRST\n",
    "    COLS = list(train.columns[1:])\n",
    "    COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "    train = train[COLS]\n",
    "\n",
    "    return train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = feature_engineer(train, PAD_CUSTOMER_TO_13_ROWS = True, targets = None)\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
